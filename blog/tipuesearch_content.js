var tipuesearch = {"pages":[{"title":"About","text":"mde.tw/lab 網誌","tags":"misc","url":"./pages/about/"},{"title":"2021 Pelican 設定修改","text":"請注意: http://fossil.kmol.info 僅支援 IPv6 網路協定. 利用 Leo Editor 開啟 CMSiMDE 中的 config/pelican.leo, 然後利用 control + i 插入一個新的節點, 將節點標題改為 @clean 20210219.md, 表示要利用 @clean 指令在 markdown 目錄中新增一個 20210219.md 的 Markdown 格式檔案. 接著從先前的網誌中複製網誌文章的標頭格式資料, 修改標題與日期, 並且留意 slug 中必須要採用唯一的檔案名稱, 然後就可以先寫網誌的摘要, 之後再利用 @others 標註將隨後子節點中的內文區全部整合到 20200219.md 檔案中. 然後就可以開始寫特定主題的網誌內容. slug 名稱必須唯一 假如你曾經見過網路上的網路文章除了英文標題外, 隨後還有一串不短的數字, 這一串數字就是與前面的文章主題結合, 然後可能用做該文章儲存的檔案名稱, 主要用來確認該主題加上數字的字串在系統中具有唯一性. 所謂同步 其實在各網誌間的所謂同步, 並非及時同步, 而是在各種可能的情況下儘量讓多方的資料內容保持相同. 那麼在完全同步之間的影響因素就是時間, 因為將資料從一系統轉到另一個系統需要時間. 以 CMSiMDE 上的 Pelican Blog 轉到 Blogger , 需要在 Leo Editor 以程式按鈕執行, 而實際操作過程需要將滑鼠停留在網誌文章節點, 然後點擊新增 Blogger 或編輯 Blogger 的程式按鈕, 一旦 Pelican Blog 的網誌文章正確存入對應的 Blogger 系統後, Blogger 會傳回 blog id, 並且透過程式安排將此一 blog id 存為該網誌文章的子節點標題, 而且是沒有內容的文章標題, 因此這些用來標註所屬 Blogger 與 blog id 的資料並不會影響 @others 導入子節點文章內容的功能. 由於目前的程式只會從網誌文章的最後一個節點存取 blog id, 因此若將同一篇網誌文章同步公開到多麼 Blogger , 新增或編輯時除了要注意滑鼠是否停留在文章主節點外, 還必須在新增與編輯過程手動搬遷這些 blog id. 修改為近端相對目錄設定並加上 Disqus 先前在建立 CMSiMDE 中 Pelican Blog 時, 一方面要兼顧 search 的回覆連結外, 還需要在導入 Disqus 時區分近端相對 URL 與遠端絕對 URL 的做法, 目前似乎可以直接採用相對目錄 URL, 並且直接加上 Disqus 相對目錄設定即可.","tags":"Weblog","url":"./2021-kmolab-pelican-setup-modification.html"},{"title":"2021 Spring 課程規劃","text":"請注意: http://fossil.kmol.info 僅支援 IPv6 網路協定. 每年的 Spring KMOLab 共開兩門課程, 網際內容管理與協同產品設計實習, 基本的課程規劃仍以承接 Fall 的計算機程式及電腦輔助設計實習為主. 重新導入 Fossil SCM 2021 年除了使用各種免費雲端儲存空間與分散式版次管理系統外, 特別又將能簡易配置在自架伺服器上的 Fossil SCM 拿了出來. 主要原因是 Fossil SCM 在功能提升與 IPv6 的環境下已經有大幅進步. 因此各種課程相關資料除了放在 Github , Gitlab 與 Heroku (只限存 500 MB), 也將同步存入近端工作站室中的實體或虛擬主機 Fossil SCM 系統中. (例如: http://mde.tw/cd2021 與 http://fossil.kmol.info/cd2021/doc/trunk/index.html 為同步資料, 其倉儲分別為 https://github.com/mdecourse/cd2021 與 http://fossil.kmol.info/cd2021 ) 五專部網際內容管理課程規劃 Spring 的網際內容管理課程分別開設在五專一精密機械工程科與四技一機械設計工程系, 因為五專一是高中一年級入學的下學期課程, 上學期只上過計算機概論, 因此五專的網際內容管理課程就從 Blogger 的網際內容管理系統導入作為開端. Blogger 是與 Google 帳號整合的 Blog 系統, 而 Blog 則是一種依照發佈時間排序的內容記錄, 五專課程一開始就是要求每一位學員利用學校配發的\"學號@gm.nfu.edu.tw\"建立自己的網際內容管理課程網誌, 並且將上學期的計算機概論課程摘要一一紀錄, 除了讓學員熟悉如何使用 Blogger 之外, 也讓學員能夠多多練習英文與中文打字, 尤其是除了中文注音輸入之外, 至少再學一套較有未來性的中文輸入法. 五專的網際內容管理系統除了 Blogger 之外, 將從如何整理各學員的 Blogger 網際連結切入, 讓學員對於 HTML 與 全球資訊網 能有初步認識, 其中將會包含如何利用 CMSiMDE 在 Github , [Gitllab], Heroku 與 Fossil SCM 中建立個人課程網頁系統. 並且讓學員逐步熟悉電腦與網路的設定與應用, 同時透過 Windows 10 64 位元操作系統上的可攜程式環境, 讓學員了解英文與程式應用的重要性. 四技部網際內容管理課程規劃 四技部的網際內容管理, 除了包含上述五專部的課程內容之外, 將要從 nfulist 程式的架構導入, 讓學員應用近端與雲端程式擷取學校教務主機中的資料. 其次還希望各學員能夠在自己的電腦上配置學校所能取得的合法 CAD 與 CAE 套件, 並且有能力採用網際程式 API 的模式延伸這些封閉套件的功能, 至少有能力可以根據 http://mde.tw/cad2020/content/HW1_SW.html 的導引, 結合初步的網際協同程式 https://github.com/mdecourse/cd2020pj1 , 開發各種與機械協同設計相關的網際延伸應用, 或者設法 改寫 CMSiMDE . 協同產品設計實習課程規劃 2021 年的協同產品設計實習所採用的規劃是三段式協同的步驟, 從兩人一組, 四人一組到最後八人一組的設計流程, 讓各學員實際了解協同設計的基本元素是人, 工具與時間, 傳統的設計工具若沒有網路的串連, 較難產生同步協同效益, 但是網路與同步協同模式也帶來許多問題. 2020 年的疫情讓全球各企業許多員工被迫必須 在家上班 , 而 work from home 的模式包含協同產品設計流程中的同步與非同步協同, 幾乎所有的成員溝通都必須透過網路與視訊工具達成. (例如: http://mde.tw/cd2020/content/Covid-19.html 與 http://mde.tw/cd2020/content/Online%20course.html ), 而這個學期的協同產品設計實習重點除了 Onshape , Coppeliasim , Webots 與 Fossil SCM 外, 也將納入 Ethercalc 的 API 應用 以及 Jitsi 視訊會議系統的使用.","tags":"Weblog","url":"./2021-spring-course-planning.html"},{"title":"Fossil SCM 與 Github 整合","text":"請注意: http://fossil.kmol.info 僅支援 IPv6 網路協定. 為了實際了解 Fossil SCM 與 Github 的同一倉儲內容資料, 應該如何整合, 特別建立了一個 fosgit 倉儲作為測試. 一開始, 利用 https://github.com/mdecourse/cmstemplate 作為樣板, 建立一個 https://github.com/mdecourse/fosgit 倉儲, 並且分別在 Ubuntu 與 Windows 10 中進行操作, 目標是分別利用 Fossil SCM 與 Github 管理 https://mde.tw/fosgit 與 http://fossil.kmol.info/fosgit/doc/trunk/index.html 兩個網站的對應倉儲. 建立 fosgit 倉儲 在 Github 登入後, 新增 fosgit 倉儲時, 在上方 template 選單, 選擇以 https://github.com/mdecourse/cmstemplate 作為 template, 意即要直接利用 CMSiMDE 建立一個動態網站與靜態網站, 名稱為 fosgit. 完成後的倉儲位於 https://github.com/mdecourse/fosgit , 透過 Github 的設定將 main 分支設為 Github Pages 的 root, 接著就可以設法將倉儲以: git clone --recurse-submodules https://github.com/mdecourse/fosgit.git 取下倉儲資料到 Ubuntu 或 Windows 10 操作系統中, 之所以需要使用 --recurse-submodules 選項的原因是 cmstemplate 倉儲帶有子模組, 使用者可以直接透過上述指令取下包含子模組的倉儲所有資料. Ubuntu 端操作 由於 fosgit 倉儲在 Fossil SCM 端希望透過 http://fossil.kmol.info/fosgit 進行管理, 為了方便, 可以直接以 ssh 登入 fossil.kmol.info 主機進行操作. 首先就是在 /home/user/repository/ 目錄中, 以 fossil init fosgit.fossil 建立 fosgit.fossil 空的倉儲檔案. 接著進入 /home/user/repository/wd/ 目錄中, 以 git clone --recurse-submodules https://github.com/mdecourse/fosgit.git 將 Github 端的倉儲 clone 至 /home/user/repository/wd/fosgit 目錄. Fossil SCM .fslckout 由於 Ubuntu Fossil SCM 倉儲的內容存在 .fslckout 檔案中, 因此 /home/user/repository/wd/fosgit 目錄中雖然已經有與 Github 遠端倉儲對應的 .git 目錄, 但還需要能與 http://fossil.kmol.info/fosgit 對應的 .fslckout, 為了取得此一資料檔案. 可以進入 fossil.kmol.info 主機中的 /home/user/repository/ 目錄, 以 fossil init fosgit.fossil 建立, 隨後則進入 /home/user/repository/wd/fosgit 目錄執行 fossil open ./../../fosgit.fossil, 將 fosgit.fossil 對應的 .fslckout 放入 /home/user/repository/wd/fosgit 目錄. 這時, 因為 http://fossil.kmol.info/fosgit settings 已經勾選 dotfiles (V), 因此 Fossil SCM 倉儲會導入 .git 目錄, 同時 Fossil SCM 的版本資料 .fslckout (或隨後的 FOSSIL ) 也會被 Github 納管. Fossil SCM addremove 指令 上述的規劃, 若從 cmsimde/ 目錄中執行 python wsgi.py, 可以在近端對倉儲內容作變更, 其中可能包括刪除倉儲中的某些檔案. 這時若要讓系統自動將已經刪除的檔案納入版次管理, 可以使用 git addremove 指令.","tags":"Weblog","url":"./fossil-scm-and-github-integration.html"},{"title":"Fossil SCM 使用案例","text":"請注意: http://fossil.kmol.info 僅支援 IPv6 網路協定. Fossil SCM 的 https://fossil-scm.org/home/doc/trunk/www/embeddeddoc.wiki 可以與靜態網頁結合應用, 唯一必須注意的是 https://fossil-scm.org/home/doc/trunk/www/defcsp.md 議題. Fossil SCM documentation 功能 先前已經建議 Fossil SCM 的倉儲可以放在 /home/user/repository/ 目錄中, 以這裡的範例分別為 /home/user/repository/cd2021.fossil 與 /home/user/repository/lab.fossil, 而這兩個倉儲的展開內容分別位於 /home/user/repository/wd/cd2021 與 /home/user/repository/wd/lab 等目錄. 透過 Fossil SCM 的 https://fossil-scm.org/home/help/http 指令與 stunnel 的結合運用可以伺服為: http://fossil.kmol.info/cd2021/doc/trunk/index.html 與 http://fossil.kmol.info/lab/doc/trunk/index.html 而這兩個 Fossil SCM 倉儲的靜態網頁與 https://mde.tw/cd2021 及 https://mde.tw/lab 內容保持同步. 且 Fossil SCM 的靜態網頁可以直接將網址中的 trunk (表示為最新版本) 換為 Fossil SCM 倉儲內容的對應版本號, 就可以直接顯示各舊版本的靜態網頁內容, 這一個功能至今連 https://pages.github.com/ 或 https://docs.gitlab.com/ee/user/project/pages/ 都還無法直接在網際介面中完成. Fossil SCM open, add 與 commit 之前已經提過, 建立 Fossil SCM 倉儲的方法: fossil init cd2021.fossil 而這個指令若直接在 /home/user/repository/ 目錄中執行, 則可以建立 cd2021.fossil 空倉儲. 這裡的規劃是將這些倉儲以 fossil open 指令, 在 /home/user/repository/wd 目錄中設法展開內容, 而且以倉儲的名稱作為展開後的目錄, 並將展開內容置入. 例如: /home/user/repository/cd2021.fossil 可以透過: 在 /home/user/repository/wd/cd2021/ 目錄中執行 fossil open ./../../cd2021.fossil 而將內容展開. 而 /home/user/repository/lab.fossil 則在 /home/user/repository/wd/lab 目錄中展開內容. 若從 Github 以: git clone --recurse-submodules https://github.com/mdecourse/cd2021.git 將 cd2021 倉儲內容取下, 而且放入 /home/user/repository/wd/cd2021/ 目錄中. 使用者就可以在 /home/user/repository/wd/cd2021/ 目錄中執行: fossil add . fossil commit -m \"add cd2021 git repository content\" 則 Fossil SCM 會將 /home/user/repository/wd/cd2021/ 已經改版的內容壓進 /home/user/repository/cd2021.fossil 倉儲中, 並透過 Fossil SCM http 將靜態網頁以 project documentation 功能伺服到 https://fossil.kmol.info/cd2021/doc/trunk/index.html . 而根據網站內容, 必須將 https://fonts.googleapis.com 放入 settings - default-csp 設定欄位中, Fossil SCM doc 網站才會允許 default-csp 設定的網站進行跨網站擷取所需的資料. 採取相同的操作步驟, 就可以將 https://mde.tw/lab 網站資料同步至 http://fossil.kmol.info/lab/doc/trunk/index.html","tags":"Weblog","url":"./fossil-scm-use-case.html"},{"title":"Fossil SCM on Ubuntu","text":"Fossil SCM 是一套完整的 軟體組態管理系統 ( Software Configuration Management ), 以 ANSI C 編寫, 其中利用 TCL 作為 Scripting 語言. 接下來將要說明如何在 Ubuntu 20.04 中安裝與配置 Fossil SCM . 這裡所要介紹的 Fossil SCM 為 http://fossil.kmol.info (只配置 IPv6 網路協定), http 網際伺服器前端採用 nginx , https 代理伺服器採用 stunnel , 主要伺服的 Software Configuration Management 套件則為 Fossil SCM . 安裝 nginx 在 Ubuntu 20.04 中安裝 nginx 非常簡單, 只要執行 sudo apt install nginx 即可. nginx 的基本設定檔案位於 /etc/nginx/sites-available/default 安裝 nginx 有兩個目的, 一方面回應 http://fossil.kmol.info , 也就是 port 80 的 WWW 伺服器. 而另外一方面則是配合 https://certbot.eff.org/lets-encrypt/ubuntufocal-nginx 以手動模式取得 stunnel https 伺服所需要的 fullchain.pem 與 privkey.prm 等兩個檔案. 安裝 Fossil SCM 在 Ubuntu 20.04 安裝 Fossil SCM 也非常簡單, 只要執行 sudo apt install fossil 即可. 但是所安裝的版本可能不是最新版, 由於安裝的 fossil 執行檔案位於 /usr/bin/fossil, 假如希望與 Windows 10 64 位元操作系統中的 Fossil SCM 對應, 可以至 https://fossil-scm.org/home/uv/download.html 下載 Linux 最新版本的 fossil, 然後以 sudo cp fossil /urs/bin/ 即可. 若要查驗 Fossil SCM 的版本, 可以使用 fossil version 指令. Fossil SCM 整個系統就只有一個 fossil 執行檔案, 而倉儲檔案則只全部壓縮在一個 SQLite 資料庫檔案中. 接下來為了配置一套可以伺服多個 Fossil SCM 倉儲的 Ubuntu 20.04 系統, 在 /home/user/ 目錄下建立 repository 目錄, 之後的所有要從遠端擷取的 Fossil SCM 倉儲都可以放在此一用戶目錄下. 至於要在此目錄下建立一個內定的 Fossil SCM 倉儲, 可以進入 /home/user/repository 目錄後 (這裡的 user 為 Ubuntu 20.04 下的用戶帳號名稱), 以 fossil init cd2021.fossil 建立一個 Fossil SCM 倉儲, 執行完後系統就會直接在命令列中顯示用來管理此一倉儲的用戶 (會使用建立倉儲的帳號, 也就是 user) 登入管理的密碼. 使用者可以選擇將此一與 user 對應的管理密碼記起來, 或者之後再使用 sqlite3 指令進入 cd2021.fossil 查詢. 假如使用者需要在 Ubuntu 環境中直接對 Fossil SCM 倉儲改版, 則建議在 /home/user/repository 目錄中再建立一個 wd 目錄 (為 working directory 的縮寫), 之後可以將位於 /home/user/repository 目錄中的各個 .fossil 內容, 在 /home/user/repository/wd 目錄中展開, 若以 /home/user/repository/cd2021.fossil 為例, 展開後將位於 /home/user/repository/wd/cd2021. 安裝 stunnel 安裝 stunnel 也很簡單, 只要執行 sudo apt install stunnel4 即可, 安裝後若要隨系統開機啟動, 則需要 sudo vi /etc/default/stunnel4, 並在檔案中加入 ENABLED=1 後存檔. 另外, 還需要 sudo vi /etc/environment, 並在檔案中加入 HTTPS=on 後存檔. 接下來為了由 stunnel 代理 Fossil SCM 的 https 伺服, 必須加入 /etc/stunnel/stunnel.conf [https] accept = 140.130.your_ipv4.ip:443 accept = 2001:288:6004:your:ipv6::ip:443 cert = /etc/stunnel/fullchain.pem key = /etc/stunnel/privkey.pem exec = /usr/bin/fossil execargs = /usr/bin/fossil http /home/user/repository/ --https --nojail --notfound cd2021 上述的 fullchain.pem 與 privkey.pem 由於尚未配置 certbot , 必須要取得合法的數位簽章檔案後, 再利用: sudo systemctl start stunnel4.service 啟動 stunnel . sudo systemctl stop stunnel4.service 關閉 stunnel , 或利用: sudo systemctl restart stunnel4.service 重新啟動 stunnel . 擷取 fullchain.pem 與 privkey.pem 這個步驟主要按照 https://certbot.eff.org/lets-encrypt/ubuntufocal-nginx 中的指令操作, 由於 Ubuntu 20.04 已經內建 snap, 因此只要執行: sudo snap install core; sudo snap refresh core sudo snap install --classic certbot sudo ln -s /snap/bin/certbot /usr/bin/certbot sudo certbot certonly --nginx 就可以在 /etc/letsencrypt/live/fossil.kmol.info/ 目錄中找到 fullchain.pem 與 privkey.pem 等兩個數位簽章檔案, 接著將此兩個檔案複製至 /etc/stunnel/ 目錄, 以便配合 /etc/stunnel/stunnel.conf 隨電腦開機啟動. 因為 certbot 的數位簽章每 90 天都要更新一次, 屆時若要手動更新可以先模擬執行: sudo certbot renew --dry-run nginx http 跳轉 https 最後一個步驟是讓 nginx 所伺服的 http://fossil.kmol.info 能夠自動跳轉到 Fossil SCM 與 stunnel 結合的 https://fossil.kmol.info 修改 /etc/nginx/sites-available/default 中的設定如下: server { listen 80; server_name fossil.kmol.info; rewrite &#94;/(.*)$ https://fossil.kmol.info/$1 permanent; }","tags":"Weblog","url":"./fossil-scm-on-ubuntu.html"},{"title":"Pelican 與 Blogger 內容同步2","text":"cmsimde 中的 Pelican blog 內容建議採用 config 目錄中的 pelican.leo 進行管理, 主要的資料管理架構採用 Leo Editor 中的 @clean 標題指令, 能夠與內文指令 @others 配合, 利用階層式的文章管理, 區隔網誌摘要與各段內容. Google Developer Console 為了能夠將 Pelican blog 在 Leo Editor 中的網誌文章推向 Blogger , 必須要從 Google developer console 取得 與 Blogger 擷取權限對應的 secret json 檔案. 實際操作流程如下: 進入 Library - > ENABLE APIS AND SERVICES -> 啟用 Blogger API v3 設定 OAuth consent screen 新增 Credentials -> Desktop-type Oauth 2.0 client -> Download JSON 即可取得 secret.json 檔案. 將 secrets.json 轉為 token.dat 轉換前必須確定系統已經安裝 google_auth_oauthlib pip install google_auth_oauthlib 接著利用下列程式將 secrets.json 轉為 token.dat, 隨後使用者就可利用此一 token.dat 將 Leo Editor 中的網誌文章內容傳送到對應的 Blogger . 下列程式在轉換過程會透過操作系統的內定瀏覽器讓使用者登入與 secrets.json 對應的帳號, 一旦通過認證就可以完成 secrets.json 轉為 token.dat 的流程. # get secrets: https://console.developers.google.com # https://developers.google.com/blogger/docs/3.0/using # pip install google_auth_oauthlib # under Mac command + b to execute import pickle import os from googleapiclient.discovery import build from google_auth_oauthlib.flow import InstalledAppFlow from google.auth.transport.requests import Request SCOPES = ['https://www.googleapis.com/auth/blogger', ] # we check if the file tBo store the credentials exists if not os.path.exists('./../../yen_gm_blogger_token.dat'): flow = InstalledAppFlow.from_client_secrets_file('./../../yen_gm_blogger_secrets.json', SCOPES) credentials = flow.run_local_server() with open('yen_gm_blogger_token.dat', 'wb') as credentials_dat: pickle.dump(credentials, credentials_dat) else: with open('yen_gm_blogger_token.dat', 'rb') as credentials_dat: credentials = pickle.load(credentials_dat) service = build('blogger', 'v3', credentials=credentials) g.es(service) 將 Pelican 文章轉往 Blogger 將 Pelican 文章轉投 Blogger 的過程包含新增與編輯, 新增的程式碼如下: from markdown import markdown from oauth2client import client #from googleapiclient import sample_tools import os # 配合使用 credential token import pickle from googleapiclient.discovery import build #from google_auth_oauthlib.flow import InstalledAppFlow #from google.auth.transport.requests import Request os.environ['TZ'] = 'Asia/Taipei' with open('./../../yen_gm_blogger_token.dat', 'rb') as credentials_dat: credentials = pickle.load(credentials_dat) service = build('blogger', 'v3', credentials=credentials) def get_cat_tag_content(data): # 請注意, 因為 data 來自 .md 的檔案 內容, 第1行為 --- # 用跳行符號分割 data_list = data.split(\"\\n\") #第 2 行為 title title= data_list[1] #第 4 行為 category category = data_list[3] #第 5 行為 tags tags = data_list[4] # 有多項資料的 content 型別為數列 # 再將第 9 行之後的資料數列串回成以跳行隔開的資料 content = \"\\n\".join(data_list[8:]) # 先將截斷摘要與內文的 pelican md 檔按符號, 換成 Blogger 的 content = content.replace(' ', ' ') # 接著若內容有 ~~~python 與 ~~~ 則換成 Wordpress 格式 #content = content.replace('~~~python', '[code lang=\"python\"]') #content = content.replace('~~~', '[/code]') return title, category, tags, content # 從目前所在節點的 body pan 中取出類別, tags 以及文章內容 # p.h 為 @clean filename.md # 因為要使用 @clean 節點掛上為後的 blogger post_id, 因此改為讀 .md 檔案 md_filename = p.h.split(\" \")[1] with open(md_filename, 'r', encoding=\"utf-8\") as content_file: md_content = content_file.read() # title_str, category_str, tags_str, content = get_cat_tag_content(p.b) title_str, category_str, tags_str, content = get_cat_tag_content(md_content) category = category_str.split(\":\")[1] tags = tags_str.split(\":\")[1].split(\",\") tags.append(category) # title 是一個單獨的字串 title = title_str.split(\":\")[1] # 將 markdown 格式 content 轉為 html content = markdown(content) # 以下處理 content 的 標題 content = content.replace(\" \", \" \") content = content.replace(\" \", \" \") # g.es(content) try: ''' users = service.users() # 取得使用者 profile 資料 user = users.get(userId='self').execute() print('網誌名稱: %s' % user['displayName']) ''' blogs = service.blogs() # 取得使用者所建立網誌名稱 blogs = blogs.listByUser(userId='self').execute() # post_id is now blogs[\"items\"][0][\"id\"] #blog_id = blogs[\"items\"][0][\"id\"] blog_id = \"2403495118140401474\" #for blog in blogs['items']: #print(blog['name'], blog['url']) posts = service.posts() # 新增網誌 post 時, 需要 post_id body = { \"kind\": \"blogger#post\", \"id\": blog_id, \"title\": title, # 利用 markdown 函式, 將 .md 的內文轉為 html, 作為 Blogger 的文章內容 \"content\": content, \"labels\": tags } insert = posts.insert(blogId=blog_id, body=body) posts_doc = insert.execute() post_id = posts_doc[\"id\"] #print(posts_doc) # 改用 credential token 後不會產生 blogger.dat #os.remove(\"blogger.dat\") # 利用最後的 child 節點來儲存 post_id to_save_post_id = p.insertAsLastChild() # 改為內文為空的節點, id 直接標在 head 標題 to_save_post_id.b = \"\" to_save_post_id.h = post_id # 因為新增節點, commander 必須 redraw c.redraw() g.es(\"post_id 為\", post_id) g.es(\"已經將資料送往 KBlogger!\") except(client.AccessTokenRefreshError): g.es(\"error\") 完成上述文章轉投至 Blogger 之後, Blogger 會傳回該文章的 post id, 而新增程式會將此 id 放在該筆 @clean 文章節點的最末端, 由於該 post id 節點只有標題而無內文, 因此即便內縮成為 @clean 的子節點, 也不會在文章中增加任何資料, 但若該網誌內容同步推向一個以上的 Blogger , 則使用者需要將該 post if 內縮外, 還需要在此 post id 節點的上屬節點增加標註, 說明該 post id 所屬的網誌標題或代號. 至於當該文章內容經過編修後, 使用者若希望將新內容推向遠端同步 Blogger , 則必須將原先新增的 Blogger post id 移至該 @clean 文章的最末端, 以便讓程式可以更新與此 post id 對應的 Blogger 文章內容. 可用於編輯 Blogger 文章的程式碼如下: from markdown import markdown from oauth2client import client #from googleapiclient import sample_tools import os # 配合使用 credential token import pickle from googleapiclient.discovery import build #from google_auth_oauthlib.flow import InstalledAppFlow #from google.auth.transport.requests import Request os.environ['TZ'] = 'Asia/Taipei' with open('./../../yen_gm_blogger_token.dat', 'rb') as credentials_dat: credentials = pickle.load(credentials_dat) service = build('blogger', 'v3', credentials=credentials) def get_cat_tag_content(data): # 請注意, 因為 data 來自 .md 的檔案 內容, 第1行為 --- # 用跳行符號分割 data_list = data.split(\"\\n\") #第 2 行為 title title= data_list[1] #第 4 行為 category category = data_list[3] #第 5 行為 tags tags = data_list[4] # 有多項資料的 content 型別為數列 # 再將第 9 行之後的資料數列串回成以跳行隔開的資料 content = \"\\n\".join(data_list[8:]) # 先將截斷摘要與內文的 pelican md 檔按符號, 換成 Blogger 的 content = content.replace(' ', ' ') # 接著若內容有 ~~~python 與 ~~~ 則換成 Wordpress 格式 #content = content.replace('~~~python', '[code lang=\"python\"]') #content = content.replace('~~~', '[/code]') return title, category, tags, content # 從目前所在節點的 body pan 中取出類別, tags 以及文章內容 # p.h 為 @clean filename.md # 因為要使用 @clean 節點掛上為後的 blogger post_id, 因此改為讀 .md 檔案 md_filename = p.h.split(\" \")[1] with open(md_filename, 'r', encoding=\"utf-8\") as content_file: md_content = content_file.read() # title_str, category_str, tags_str, content = get_cat_tag_content(p.b) title_str, category_str, tags_str, content = get_cat_tag_content(md_content) category = category_str.split(\":\")[1] tags = tags_str.split(\":\")[1].split(\",\") tags.append(category) # title 是一個單獨的字串 title = title_str.split(\":\")[1] # 將 markdown 格式 content 轉為 html content = markdown(content) # 以下處理 content 的 標題 content = content.replace(\" \", \" \") content = content.replace(\" \", \" \") # g.es(content) try: blogs = service.blogs() # 取得使用者所建立網誌名稱 blogs = blogs.listByUser(userId='self').execute() #blog_id = blogs[\"items\"][0][\"id\"] blog_id = \"2403495118140401474\" # 設法取得原 post 的 id postid_outline = p.getLastChild() # 直接從標題取得 post 的 id 號碼 post_id = postid_outline.h posts = service.posts() # 更新網誌文章時的 body body = { \"kind\": \"blogger#post\", \"title\": title, \"content\": content } # need to save postId to outline head update = posts.update(blogId=blog_id, postId=post_id, body=body, publish=True) update_doc = update.execute() # 使用 credential token 後, 無需刪除 blogger.dat #os.remove(\"blogger.dat\") g.es(\"post_id 為\", post_id) g.es(\"已經將更新資料送往 K Blogger!\") except(client.AccessTokenRefreshError): g.es(\"error\")","tags":"Weblog","url":"./sync-pelican-and-blogger-content2.html"},{"title":"資料儲存的永續性","text":"假如將時間倒轉 20 年, 看看當時的電腦程式課程在教些什麼? 大家是如何上課, 結果應該會讓現在這些初出茅廬, 剛剛成年的大一生非常驚訝. 是的, 當年並沒有人手一機, 上課是需要抄筆記的...... 而且當時全球科技界正度過所謂的千禧年之禍, 利用電腦程式產生中文字仍處於 Big-5 的陰影下, 倚天中文仍然到處可見, 即使處在所謂的數位科技前緣, 某些人手上已經有小而美的易利信手機, 口袋裡也放著一個由 HTC 打造的頗有重量 HP PDA , 但所謂數位資料的永續性, 距離仍然很遠, 因此二十年多年後, 當時能留下與上課有關的數位資料非常有限. 之後就在 Google 逐漸成熟, 而 Facebook 騰空出世 7 年後的 2011年, Red Hat 推出可以免費使用的 Openshift , 不僅能夠伺服 PHP 與 Python, 還可免費存放各種數位資料, 當時以為資料終於可以永續存放的假象, 到 2016 年夢想逐漸破滅, 還好 2016 年之後有 Github 接手, Heroku 也很意外地從 2007 年活到現在, 目前, Github 與 Heroku (只能儲存 500 MB), 加上 Gitlab 的同步資料備份與 Google Drive 上的大檔案存放, 全球網友前撲後繼用隱私換取數位資料免費存放的所謂永續性, 似乎終於有了眉目. 目前教育版的 Google Drive 仍不限容量, 但也許未來的某一天這樣的所謂永續仍會畫上休止符, 大家仍必須有所因應. 資料存至 Google Drive 從 https://github.com/mdecourse/cd2020pj1/blob/master/myflaskapp.py 可以看出如何利用 Google Drive API, 在網際環境中將數位檔案送到特定伺服器之外, 還能利用 AJAX 存備份至特定 Google Drive 目錄. @app.route('/saveToDB' , methods=['POST']) @login_required def saveToDB(): \"\"\"axuploader.js 將檔案上傳後, 將上傳檔案名稱數列, 以 post 回傳到 Flask server. 截至這裡, 表示檔案已經從 client 上傳至 server, 可以再設法通過認證, 將 server 上的檔案上傳到對應的 Google Drive, 並且在上傳後的 GDrive 目錄, 設定特定擷取權限 (例如: 只允許 @gm 用戶下載. 以下則可將 server 上傳後的擷取目錄與 GDrive 各檔案 ID 存入資料庫, 而檔案擷取則分為 server 擷取與 GDrive 擷取等兩種 url 連結設定 \"\"\" if request.method == \"POST\": files = request.form[\"files\"] # split files string files = files.split(\",\") # files 為上傳檔案名稱所組成的數列 for i in range(len(files)): # 逐一將已經存在 server downloads 目錄的檔案, 上傳到 GDrive uploaded 目錄 fileName = files[i] fileLocation = _curdir + \"/downloads/\" + fileName mimeType = mimetypes.MimeTypes().guess_type(fileLocation)[0] # for GDrive v2 #gdriveID = uploadToGdrive(fileName, mimeType) # for GDrive v3 gdriveID = uploadToGdrive3(fileName, mimeType) fileSize = str(round(os.path.getsize(fileLocation)/(1024*1024.0), 2)) + \" MB\" date = datetime.datetime.now().strftime(\"%b %d, %Y - %H:%M:%S\") user = session.get(\"user\") print(user + \"|\" + str(fileSize) + \"|\" + str(mimeType) + \"|\" + gdriveID) # 逐一將上傳檔案名稱存入資料庫, 同時存入mimeType, fileSize 與 gdriveID # 資料庫欄位 #g.db.execute('insert into grouping (user , date, fileName, mimeType, fileSize, memo) values (?, ?, ?, ?, ?, ?)',(user, date, fileName, mimeType, fileSize, \"memo\")) #g.db.commit() #flash('已經新增一筆 upload 資料!') return \"Uploaded fileName and gdriveID save to database\" def uploadToGdrive(fileName, mimeType): gauth = GoogleAuth() # 必須使用 desktop 版本的 client_secrets.json gauth.LoadClientConfigFile(\"./../gdrive_desktop_client_secrets.json\") drive = GoogleDrive(gauth) ''' # View all folders and file in your Google Drive fileList = drive.ListFile({'q': \"'root' in parents and trashed=false\"}).GetList() for file in fileList: print('Title: %s, ID: %s' % (file['title'], file['id'])) # Get the folder ID that you want # 檔案會上傳到根目錄下的 uploaded 目錄中 if(file['title'] == \"uploaded\"): fileID = file['id'] ''' # GDrive 上 uploaded 目錄的 fileID with open(\"./../gdrive_uploaded_id.txt\", 'r') as content_file: fileID = content_file.read() # 由上述目錄外的檔案讀取 uploaded 目錄對應 ID #fileID = \"your_folder_file_ID\" # 上傳檔案名稱為輸入變數 #fileName = \"DemoFile.pdf\" filePath = _curdir + \"/downloads/\" # parents 為所在 folder, 亦即 uploaded 目錄, fileID 為 uploaded 目錄的 ID file1 = drive.CreateFile({\"mimeType\": mimeType, \"parents\": [{\"kind\": \"drive#fileLink\", \"id\": fileID}], \"title\": fileName}) file1.SetContentFile(filePath + fileName) file1.Upload() # Upload the file. # 傳回與上傳檔案對應的 GDrive ID, 將會存入資料庫 gdiveID 欄位 return file1['id'] #print('Created file %s with mimeType %s' % (file1['title'], file1['mimeType'])) #print(\"upload fileID:\" + str(file1['id'])) # 以下為下載檔案測試 # file2 = drive.CreateFile({'id': file1['id']}) #file2.GetContentFile('./test/downloaded_ModernC.pdf') # Download file as 'downloaded_ModernC.pdf under directory test'. ''' file1.Trash() # Move file to trash. file1.UnTrash() # Move file out of trash. file1.Delete() # Permanently delete the file. ''' def uploadToGdrive3(fileName, mimeType): # get upload folder id # GDrive 上 uploaded 目錄的 fileID with open(\"./../gdrive_uploaded_id.txt\", 'r') as content_file: folderID = content_file.read() creds = None with open('./../gdrive_write_token.pickle', 'rb') as token: creds = pickle.load(token) # 讀進既有的 token, 建立 service driveService = build('drive', 'v3', credentials=creds) metadata = { 'name': fileName, 'mimeType': mimeType, # 注意: 必須提供數列格式資料 'parents': [folderID] } filePath = _curdir + \"/downloads/\" + fileName media = MediaFileUpload(filePath, mimetype=mimeType, chunksize=1024*1024, resumable=True ) gdFile = driveService.files().create( body=metadata, media_body=media, fields='id' ).execute() fileID = gdFile.get(\"id\") return fileID 上述程式利用較新的 GDrive V3 上傳資料之前, 可攜系統必須安裝 google-api-python-client: # for uploadToGDrive3 # pip install google-api-python-client # https://github.com/googleapis/google-api-python-client import pickle from googleapiclient.discovery import build from apiclient.http import MediaFileUpload Github, Gitlab 與 Fossil SCM 針對 Github 與 Gitlab 的操作, 可以參考 https://git-scm.com/book/en/v2 , 但是 Fossil SCM 的參考資料則相對較少, 以下將針對 Fossil SCM 的應用稍加說明, 為了因應未來上述各種網際免費數位儲存資料系統的更迭, 在近端配置 Fossil SCM , 並用 BD-R or BD-RE (25GB) 進行備份, 也是一個不錯的資料永續儲存方案. Fossil SCM 的使用非常簡單, 只要配合操作系統從 https://fossil-scm.org/home/uv/download.html 下載相應版本, 並讓系統可以執行 fossil.exe (以 Windows 10 為例) 即可, 唯一要注意的是若操作過程牽涉兩個不同操作系統, 必須透過 fossil version 查驗雙方的版本是否相同. 有關 Fossil SCM 的先前參考資料, 可參閱 Fossil SCM 簡介 . Ubuntu 安裝 fossil scm 使用 sudo apt install fossil 安裝 Fossil SCM 所取得的版本可以利用 fossil version 檢查. 若版本並非最新版本或與 Windows 10 所用的版本相同, 可以至 https://fossil-scm.org/home/uv/download.html 下載最新的 fossil 後, 以 sudo cp /home/user/fossil /usr/bin/, 然後再透過 fossil version 查驗是否已經更新為最新版本. 安裝 stunnel4 由於 Fossil SCM 並無 https 啟動功能的設置, 因此在實作上必須透過 stunnel SSL 代理主機啟動 https 伺服功能. 首先安裝 stunnel4: sudo apt install stunnel4 接下來將系統環境設為 HTTPS: sudo vi /etc/environment 加入 HTTPS=on 並且在 /etc/default/stunnel4 中加入 ENABLED=1 然後透過 sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout localhost.key -out localhost.crt, 在 /etc/stunnel/ 目錄中建立所需的 localhost.key 與 localhost.crt 同時建立 /etc/stunnel/stunnel.conf 如下: [https] accept = your_IPv4_ip:443 accept = :::443 cert = /etc/stunnel/localhost.crt key = /etc/stunnel/localhost.key exec = /usr/bin/fossil execargs = /usr/bin/fossil http /home/user/repository/ --https --nojail --notfound cd2021 實際配置下, 使用 :::443 並無法讓 stunnel 綁定至系統的 ipv6 網址, 必須使用: [https] accept = 140.xxx.xxx.xxx:443 accept = 2001:288:6004:xx::1:443 cert = /etc/stunnel/localhost.crt key = /etc/stunnel/localhost.key exec = /usr/bin/fossil execargs = /usr/bin/fossil http /home/user/repository/ --https --nojail --notfound cd2021 似乎 stunnel 會自動取最後的 :443 作為 port, 而無需如 https://[ipv6 address]:443 中以 [] 隔開 ipv6 網址與埠號. execargs = /usr/bin/fossil http /home/user/repository/ --https --nojail --notfound cd2021 設定的意思為 stunnel 代理啟動的指令為 fossil http, 指定 /home/yser/repository/ 作為倉儲目錄, 可以透過 URL 加上倉儲名稱伺服多個 repo.fossil 倉儲, 隨後的 --https 表示要使用 https 協定擷取資料, --nojail 表示不要使用 root 權限啟動, 且不進入 jail 模式, --notfound cd2021 表示內定 https URL 擷取的倉儲為 /home/user/repository/cd2021.fossil 啟動-停止-重新啟動 stunnel4.service sudo systemctl start stunnel4.service sudo systemctl stop stunnel4.service sutod systemctl restart stunnel4.service","tags":"Weblog","url":"./data-sustainablity.html"},{"title":"2021 開春","text":"2021 年伊始, 機器學習的程式從原先簡單的演化, 進展到能夠有效控制具有亂數的決策系統, 科技的發展讓人類的工作更加兩極化, 一方可持續開發指使電腦軟硬體從事工作, 而另一方則幾乎必須完全按照電腦軟硬體的指示與命令行事. 這樣的發展似乎已經沒了退路.","tags":"Weblog","url":"./starting-2021.html"},{"title":"使用 Leo Editor","text":"Leo Editor 的使用可以從 LEO_EDITOR 的環境變數設定開始, 讓多元的大綱管理流程, 成為您程式開發與資料管理上的一大利器. Leo Editor 與 SciTE 當使用 KMOLab 所建立的 Windows 64 位元操作系統環境下的可攜系統時, 只要在 start.bat 中, 加入 LEO_EDITOR 環境變數的設定, 使用者就可以將大綱中的 Python 程式, C 程式, Dart 程式或 Lua 程式碼, 直接帶到 SciTE 編輯器中執行. REM 設定 Leo 所用的編輯器 set LEO_EDITOR=%Disk%:\\wscite\\SciTE.exe 對於比較簡單的 Python 程式段, 則可以直接在大綱對應的內文區, 直接透過 Ctrl + b 按鈕執行, 而比較複雜需要獨立執行的 Python 程式段, 則建議利用執行緒執行，以免拖累 Leo Editor 本體的執行. import os import subprocess import threading import http.server, ssl def domake(): # build directory os.chdir(\"./../\") server_address = ('localhost', 5443) httpd = http.server.HTTPServer(server_address, http.server.SimpleHTTPRequestHandler) httpd.socket = ssl.wrap_socket(httpd.socket, server_side=True, certfile='localhost.crt', keyfile='localhost.key', ssl_version=ssl.PROTOCOL_TLSv1) print(os.getcwd()) print(\"5443 https server started\") httpd.serve_forever() # 利用執行緒執行 https 伺服器 make = threading.Thread(target=domake) make.start() Leo Editor 的入門不容易 從 Leo Editor 的 開發歷史 來看, 自 1995 年啟動, 歷經使用 Borland C 與 Tkinter 等階段, 直到 2012 年採 Qt 作為圖形介面之後, 才開始穩定下來. 現在更有 LeoVue 與 LeoInteg 等兩個專案, 分別利用 Javascript 與 Typescript, 將 Leo Editor 帶進網際與 Visual Studio Code 的應用領域. 假如再加上最近 Qt 喊出的使用授權大變更, 接下來的 Leo Editor 開發可能即將面臨一波更大的轉變. Leo Editor 的入門之所以不容易, 源自於其早期訂下的長遠目標, 因為試圖結合大綱編輯器與 Literate Programming 本來就是一條艱困的程式開發道路. 而且 Leo Editor 程式設計的思維大量依賴 Python 語法與 Vim 原理 , 同一個 Leo Editor 版本在不同操作系統的使用流程, 又因為各種原因而導致有許多獨門克服方法. 即便是同時使用 Mac, Linux 與 Windows 的老手, 都可能因為 Leo Editor 程式碼的快速改版而經常碰壁, 更別提初學者面對各種使用門檻時的無奈與慌亂. 但是又何奈 KMOLab 使用 Leo Editor 的時間已經超過 10 年, 期間仍然找不到其他替代工具. 只能利用 SciTE 來補足 Leo Editor 在 parse 大檔案過程效率的不足.","tags":"Leo Editor","url":"./how-to-use-leo-editor.html"},{"title":"代理主機維護策略","text":"昨天又失去一台 HP 代理主機, 也就是編號 42 的 Squid Proxy Server. 因此目前只剩下 4, 53 與 69 等三台. 雙協定支援代理主機的需求 也許大家會存疑, 機械設計科系為何需要自行安裝維護網路代理主機？假如根據學校多年前回覆, 之所以拆掉校級的代理主機設置, 原因是聯外頻寬已經很足夠, 因此不需要網路代理主機. 但是, 這種假設是, 系上的 IPv4 數量足夠, 而大部分的外部伺服器都已經支援 IPv6, 但是對於平日電腦總數量超過 300 台的機械設計系, 希望上課時讓每一位學員都能將課程資料存取於 Github.com, 這兩個條件都不存在. 因此, 從電腦輔助設計室上課的需求來看, 採用 IPv4 NAT 的模式, 並無足夠的頻寬讓 至少 50 台電腦快速直接對 Github.com 連線, 而如眾所知, Github.com 目前尚不支援 IPv6 網路協定. 因此, 2-3 台能夠同時支援 IPv4 與 IPv6 網路協定的代理主機, 似乎是可行的方案之一. 維護全時運作主機的可能方案 假如以電腦輔助設計室每週 40 堂課計算, 其中只有至多 14 堂課需要使用網路代理主機, 理論上並沒有必要全時讓這些代理主機運作, 而只要維持一台連內 (69), 一台連外 (4), 其餘的 IPv4 伺服器 IP 位址, 可以交由每班中至多 5 個分組的組長, 以虛擬主機 bridged 網路的方式各自管理分組中的代理主機, 其中可能的編號將有 (24, 32, 34, 39, 42）等五台. 其中, 因為在上學期的課程有大一的計算機程式與大二的電腦輔助設計實習課程, 而下學期的課程則有大一的網際內容管理與大二的協同產品設計實習, 正好可以在各課程中安排學長與學弟妹共同維護這五台代理主機的互動傳承內容. Squid 代理主機的安裝 以 Ubuntu 20.04 伺服器主機為例, 安裝 Squid Proxy 伺服器: sudo apt install squid 接下來, 利用 /etc/squid/squid.conf 進行配置: # 定義可以連線電腦網路位置範圍或特定 IP acl cad_lab src 192.130.17.0/24 acl cad_lab src 192.127.237.33 acl cad_lab src 2001:288::/64 # 定義可以連線通過的埠號 acl SSL_ports port 443 acl Safe_ports port 80 # http acl Safe_ports port 88 acl Safe_ports port 89 #acl Safe_ports port 21 # ftp acl SSL_ports port 8843 acl SSL_ports port 5443 acl SSL_ports port 8443 acl Safe_ports port 8443 acl SSL_ports port 9443 acl Safe_ports port 9443 acl SSL_ports port 22 acl Safe_ports port 22 acl Safe_ports port 443 # https acl Safe_ports port 1025-65535 # unregistered ports acl Safe_ports port 280 # http-mgmt acl Safe_ports port 488 # gss-http acl Safe_ports port 591 # filemaker acl Safe_ports port 777 # multiling http acl CONNECT method CONNECT # 除了前面定義的安全埠號外, 一律拒絕連線 # Deny requests to certain unsafe ports http_access deny !Safe_ports # 除了前面定義的安全埠號外, 一律不准連線 # Deny CONNECT to other than secure SSL ports http_access deny CONNECT !SSL_ports # 只允許前面定義的網路 IP 電腦連線, 其餘一律禁止 http_access allow cad_lab http_access deny all # Only allow cachemgr access from localhost http_access allow localhost manager http_access deny manager #http_access allow localnet http_access allow localhost # And finally deny all other access to this proxy http_access deny all # Squid normally listens to port 3128 http_port 3128 #cache_dir ufs /var/spool/squid 100 16 256 icp_port 3130 icp_access allow all cache_dir ufs /var/spool/squid 2000 16 256 cache_peer 192.130.17.4 sibling 3128 3130 cache_peer 192.130.17.42 sibling 3128 3130 cache_peer 192.130.17.53 sibling 3128 3130 # # Add any of your own refresh_pattern entries above these. # refresh_pattern &#94;ftp: 1440 20% 10080 refresh_pattern &#94;gopher: 1440 0% 1440 refresh_pattern -i (/cgi-bin/|\\?) 0 0% 0 refresh_pattern (Release|Packages(.gz)*)$ 0 20% 2880 refresh_pattern . 0 20% 4320 max_filedesc 40960 cache_mem 4000 MB 修改 /etc/squid/squid.conf 後, 以: sudo systemctl restart squid 重新啟動. 假如要讓 Virtualbox 虛擬主機與 Windows 10 host 啟動開啟虛擬代理主機, 可以設定使用 VBoxVmService , 但是 5.X 的 Virtualbox 必須與 VBoxVmService 5.X 版配合, 而 6.X 的版本也必須互動升級配置. 後記: 42 是一台 HP ML 30 gen9 的機器, 2017 安裝的 Ubuntu 在前幾天停止運作後, 直接將 Host 裝上 Win 10, 因無法從 USB 安裝, 只能用 blueray dvd 重新安裝, 然後外部設為 39, 然後將虛擬 proxy 伺服器設為 42, 目前仍然加入服役中.","tags":"Network","url":"./stratege-for-proxy-servers.html"},{"title":"高風險聯網設備","text":"前幾天, 感謝校方送來一份通知, 列出系上共有 40 多台所謂的高風險聯網設備. 其中有 8 台 Linux 代理主機必須配合更新套件, 並且限定可連線管理的 IP 位址範圍. Ubuntu 伺服器 設計系目前共有三台實體虛擬主機與一台虛擬代理主機, 四台符號名稱伺服器, 以及兩台虛擬的 WWW 伺服器主機. 其中系上的符號名稱伺服器原先安裝 Ubuntu 18.04, 必須升級為 20.04, 四台符號名稱伺服器與 WWW 伺服器則需要限制 ssh 的連線範圍. 針對非開發版本的 Ubuntu 18.04 可以參考 https://www.linuxtechi.com/upgrade-ubuntu-18-04-lts-to-ubuntu-20-04-lts/ 升級為 20.04. 舊版的 nginx, 若要升級為較新版本, 則可參考 https://devopscraft.com/how-to-compile-nginx-from-source-on-ubuntu-20-04/ 自行編譯安裝. ufw 防火牆 以代理主機而言, 除了限制可連線 ssh 的 IP 範圍外, 還需要讓同區段的電腦可以對 3128 埠號連線; sudo -s ufw status ufw allow from your_ipv4_or_ipv6_ip ufw allow from 2001:288::/16 to any port 22 ufw deny 22 ufw allow from 2001:288::/16 to any port 3128 ufw deny 3128 ufw enable 其次, 若要刪除原先 ufw 的設定可以使用 ufw reset, 若要暫時關閉 ufw, 採用 ufw disable. 符號名稱的部分, 需要限制 port 22 連線外, 必須讓所有主機都能對 port 53 連線: sudo -s ufw status ufw allow from your_ipv4_or_ipv6_ip ufw allow from 2001:288::/16 to any port 22 ufw deny 22 ufw allow 53 ufw enable WWW 伺服器若採用 port 80 與 443 配置, 則需要對所有主機開放, port 5443 若執行 Fossil SCM, 也必須開放, 其他也是對 port 22 有連線範圍的限制. sudo -s ufw status ufw allow from your_ipv4_or_ipv6_ip ufw allow from 2001:288::/16 to any port 22 ufw deny 22 ufw allow 80 ufw allow 443 ufw allow 5443 ufw enable 最後, 則是附上 電腦輔助設計室電腦規劃 與 網路安全 參考資料.","tags":"Network","url":"./high-risk-networking-devices.html"},{"title":"網際內容管理 Ｗ13","text":"之所以在機械設計工程系開設網際內容管理課程, 起源於多年前的所謂製商整合科技教育改進計畫, 當時參與的科系有機械設計系, 自動化工程系, 工業管理系與資訊管理系, 同時開設的課程還有協同產品設計實習, 基因演算與產品生命週期管理. 網際內容管理課程目標 這項計畫與其他所謂的跨領域學程的命運沒有太大的差異, 計畫補助經費結束, 大家各自回巢, 留下一堆陳年資訊系統設備, 還有這門網際內容管理與協同產品設計實習. 網際內容管理課程開設在機械科系的主要任務, 是要鼓勵工程師善用全球資訊網的無遠弗屆, 與其他領域工程師執行協同設計, 自 2012 年起 Onshape 已經成功在曾經開發 Solidworks 的基礎上, 證明瀏覽器, 平板電腦與手機, 都可以是機械設計工程師開發產品的平台, 無需受限於單機安裝, 必須自行看顧版本更新, 徹底脫離沒有產品資料管理系統, 就無法協同進行產品開發的舊時代. 當然, Onshape 雖然定位為電腦輔助機械設計與分析管理平台, 但是真正能夠編寫 Web based 程式前後端, 並且與 Parasolid 核心程式庫進行圖形介面與觸控互動, 絕非出自通常只上過一門 [計算機程式] 課程的機械工程師, 而是來自一群號稱 Full stack web developers 的資訊科系研究工程師. 儘管如此, 對於必須在 Onshape 上利用 Featurescript 進行各種 2D 與 3D 零組件客製設計的機械工程師, 仍需具備一定程度的網際程式能力. 因此, 在四技部的網際內容管理課程, 定位為接續計算機程式課程, 預計培養未來在電腦輔助設計實習與協同產品設計實習等課程, 負責建置實體與虛擬主機, 搭建網際機械設計管理系統的協同人員, 而五專部的網際內容管理課程, 則定位在承接計算機概論課程, 讓高一程度的學員, 能夠了解網際軟硬體的基本架構外, 也能夠利用分散式版次管理建立網站, 管理網誌並利用基本的程式方法, 讓 Google Blogger 與 CMSiMDE 中的 Pelican 網誌內容同步. Leo Editor 要讓兩套架構完全不同的網誌系統內容同步, 可以採取各種程式方法, 這裡是透過 Leo Editor 大綱編輯程式中的節點按鈕與節點編輯特性完成. Leo Editor 允許使用者透過不同的 節點指令 , 進行特定文字檔案的編輯管理, 其中的 clean 節點指令, 最適合用來編輯 Pelican Blog 的 Markdown 文章內容, 因為 clean 允許將一篇文章以從屬架構的節點內容分割, 當使用者利用 button 中的 Python 程式段, 試圖將 Pelican 網誌的文章從 Markdown 格式, 轉為 html 檔案, 並且通過 Google Blogger API 的 credential 認證, 將網誌的 html 格式文章, 轉貼到對應的 Blogger 系統之後, 可以取得該網誌的 id, 並將此 id 儲存在該 Pelican 文章編輯大綱中, clean 節點下層的最末端, 之後的內容改版, 就可以依據此一 Blogger 文章 id, 循相同的授權模式, 將改版內容送至 Google Blogger . 按鈕程式所需模組 為了利用 button 中的 Python 程式將文章發佈至 Google Blogger , 可攜程式系統需要安裝 google-api-python-client 與 oauth2client 模組. pip install google-api-python-client oauth2client 接下來則是取得與所要同步的 Google Blogger 認證檔案.","tags":"WCM","url":"./wcm-w13-ubuntu-and-blogs.html"},{"title":"同步 Pelican 與 Blogger 網誌內容","text":"在先前的 CMSiMDE 架構中, 曾經設法讓 Pelican 與 Ｗordpress 的內容同步 , 相同的概念, 也可以在 Leo Editor 中, 讓 Pelican 的網誌文章與 Google Blogger 保持同步. 按鈕與節點標題 Leo Editor 中可以設置按鈕執行 Python 程式, 其中搭配節點的標題內容存取, 可以應用在 Pelican 與 Blogger 的網誌內容同步. 由於目前使用的 Pelican, 在 markdown 目錄中編寫 .md 檔案, 然後再設法以 Pelican 指令與設定檔, 將所有的 .md 檔案轉為 blog 目錄中的網誌內容. 其中, 若能將個別的 .md 檔案先轉為 html 後, 再利用 Google Blogger API 的 Python 程式將各網誌 html 檔案送至對應帳號下的 Blogger 網誌系統, 將可以將一份內容分別同步到 Pelican 與 Blogger. 新增 Blogger 文章 add_to_blogger 按鈕程式: from markdown import markdown from oauth2client import client from googleapiclient import sample_tools import os argv = \"\" # 認證並建立服務 # name of the api is \"blogger\", version is \"v3\" # description of the api is __doc__ # file name of the application: location of client_secrets.json service, flags = sample_tools.init( argv, 'blogger', 'v3', __doc__, \"./../../client_secrets.json\", scope='https://www.googleapis.com/auth/blogger') def get_cat_tag_content(data): # 請注意, 因為 data 來自 .md 的檔案 內容, 第1行為 --- # 用跳行符號分割 data_list = data.split(\"\\n\") #第 2 行為 title title= data_list[1] #第 4 行為 category category = data_list[3] #第 5 行為 tags tags = data_list[4] # 有多項資料的 content 型別為數列 # 再將第 9 行之後的資料數列串回成以跳行隔開的資料 content = \"\\n\".join(data_list[8:]) # 先將截斷摘要與內文的 pelican md 檔按符號, 換成 Blogger 的 # 但是只換第一個 content = content.replace(' ', ' ', 1) # 接著若內容有 ~~~python 與 ~~~ 則換成 Wordpress 格式 #content = content.replace('~~~python', '[code lang=\"python\"]') #content = content.replace('~~~', '[/code]') return title, category, tags, content # 從目前所在節點的 body pan 中取出類別, tags 以及文章內容 # p.h 為 @clean filename.md # 因為要使用 @clean 節點掛上為後的 blogger post_id, 因此改為讀 .md 檔案 md_filename = p.h.split(\" \")[1] with open(md_filename, 'r', encoding=\"utf-8\") as content_file: md_content = content_file.read() # title_str, category_str, tags_str, content = get_cat_tag_content(p.b) title_str, category_str, tags_str, content = get_cat_tag_content(md_content) category = category_str.split(\":\")[1] tags = tags_str.split(\":\")[1].split(\",\") tags.append(category) # title 是一個單獨的字串 title = title_str.split(\":\")[1] # 將 markdown 格式 content 轉為 html content = markdown(content) # 以下處理 content 的 <h2>標題 content = content.replace(\"<h2>\", \"<h2><font size='4'>\") content = content.replace(\"</h2>\", \"</font></h2>\") # g.es(content) try: ''' users = service.users() # 取得使用者 profile 資料 user = users.get(userId='self').execute() print('網誌名稱: %s' % user['displayName']) ''' blogs = service.blogs() # 取得使用者所建立網誌名稱 blogs = blogs.listByUser(userId='self').execute() # post_id is now blogs[\"items\"][0][\"id\"] blog_id = blogs[\"items\"][0][\"id\"] #for blog in blogs['items']: #print(blog['name'], blog['url']) posts = service.posts() # 新增網誌 post 時, 需要 post_id body = { \"kind\": \"blogger#post\", \"id\": blog_id, \"title\": title, # 利用 markdown 函式, 將 .md 的內文轉為 html, 作為 Blogger 的文章內容 \"content\": content, \"labels\": tags } insert = posts.insert(blogId=blog_id, body=body) posts_doc = insert.execute() post_id = posts_doc[\"id\"] #print(posts_doc) os.remove(\"blogger.dat\") # 利用最後的 child 節點來儲存 post_id to_save_post_id = p.insertAsLastChild() # 改為內文為空的節點, id 直接標在 head 標題 to_save_post_id.b = \"\" to_save_post_id.h = post_id # 因為新增節點, commander 必須 redraw c.redraw() g.es(\"post_id 為\", post_id) g.es(\"已經將資料送往 Blogger!\") except(client.AccessTokenRefreshError): g.es(\"error\") 編輯 Blogger 文章 edit_to_blogger 按鈕程式: from markdown import markdown from oauth2client import client from googleapiclient import sample_tools import os argv = \"\" # 認證並建立服務 # name of the api is \"blogger\", version is \"v3\" # description of the api is __doc__ # file name of the application: location of client_secrets.json service, flags = sample_tools.init( argv, 'blogger', 'v3', __doc__, \"./../../client_secrets.json\", scope='https://www.googleapis.com/auth/blogger') def get_cat_tag_content(data): # 請注意, 因為 data 來自 .md 的檔案 內容, 第1行為 --- # 用跳行符號分割 data_list = data.split(\"\\n\") #第 2 行為 title title= data_list[1] #第 4 行為 category category = data_list[3] #第 5 行為 tags tags = data_list[4] # 有多項資料的 content 型別為數列 # 再將第 9 行之後的資料數列串回成以跳行隔開的資料 content = \"\\n\".join(data_list[8:]) # 先將截斷摘要與內文的 pelican md 檔按符號, 換成 Blogger 的 content = content.replace(' ', ' ') # 接著若內容有 ~~~python 與 ~~~ 則換成 Wordpress 格式 #content = content.replace('~~~python', '[code lang=\"python\"]') #content = content.replace('~~~', '[/code]') return title, category, tags, content # 從目前所在節點的 body pan 中取出類別, tags 以及文章內容 # p.h 為 @clean filename.md # 因為要使用 @clean 節點掛上為後的 blogger post_id, 因此改為讀 .md 檔案 md_filename = p.h.split(\" \")[1] with open(md_filename, 'r', encoding=\"utf-8\") as content_file: md_content = content_file.read() # title_str, category_str, tags_str, content = get_cat_tag_content(p.b) title_str, category_str, tags_str, content = get_cat_tag_content(md_content) category = category_str.split(\":\")[1] tags = tags_str.split(\":\")[1].split(\",\") tags.append(category) # title 是一個單獨的字串 title = title_str.split(\":\")[1] # 將 markdown 格式 content 轉為 html content = markdown(content) # 以下處理 content 的 <h2>標題 content = content.replace(\"<h2>\", \"<h2><font size='4'>\") content = content.replace(\"</h2>\", \"</font></h2>\") # g.es(content) try: blogs = service.blogs() # 取得使用者所建立網誌名稱 blogs = blogs.listByUser(userId='self').execute() blog_id = blogs[\"items\"][0][\"id\"] # 設法取得原 post 的 id postid_outline = p.getLastChild() # 直接從標題取得 post 的 id 號碼 post_id = postid_outline.h posts = service.posts() # 更新網誌文章時的 body body = { \"kind\": \"blogger#post\", \"title\": title, \"content\": content } # need to save postId to outline head update = posts.update(blogId=blog_id, postId=post_id, body=body, publish=True) update_doc = update.execute() os.remove(\"blogger.dat\") g.es(\"post_id 為\", post_id) g.es(\"已經將更新資料送往 Blogger!\") except(client.AccessTokenRefreshError): g.es(\"error\") 從 Blogger 取回內容 在 Pelican 與 Ｗordpress 的內容同步 中, 可以從 Wordpress 取回網誌內容, 然後新增到 Pelican, 在此因為網誌文章的建立以 CMSiMDE 倉儲中的 Pelican 網誌為主, Blogger 只是附屬備份網誌, 所以就不再從新增的 Google Blogger 取回網誌文章. 參考資料 https://developers.google.com/blogger","tags":"Weblog","url":"./sync-pelican-and-blogger-content.html"},{"title":"Virtualbox Ubuntu 虛擬主機網路設定","text":"利用 Virtualbox 建立 Ubuntu 20.04 伺服器的虛擬主機, 可以讓使用者透過便捷的網路設定, 了解不同主機連線配置的特性外, 也能同時測試跨操作系統平台套件在 Windows 與 Ubuntu 環境執行的差異. 修課學員只要登入 ＠gm 帳號後, 就可下載 Ubuntu 20.04 虛擬主機 (或下載 Ubuntu 20.04 W12 虛擬主機 ), 並匯入 Windows 10 環境所安裝的 Virtualbox . 接下來就必須了解如何使用虛擬主機的 NAT Network 網路設定. 讓虛擬主機連上廣域網路 能直接讓 Virtualbox 虛擬主機連上網路的設定, 可以選擇 NAT, NAT Network 與 Bridged 等三種設定. 詳細的說明可以參考 Virtualbox Network Setting , Virtualbox 5.1.22 User Manual , Virtualbox 6.1.8 User Manual 中的說明. 假如需要利用 Python 程式透過 COM 操控 Virtualbox 中的虛擬主機, 則可以參考 Virtualbox 5.1.22 Programming Guide 與 Virtualbox 6.1.8 Programming Guide 中的說明. 在目前的網際內容管理與協同產品設計課程應用上, 以 NAT Network 的設置最合需求. 因為 Ubuntu 20.04 虛擬主機可以透過 Windows 10 Host 的 IPv4 或 IPv6 網路設定連外. 同時 Ｗindows 10 上的瀏覽器與 Python 程式可以透過內部網路對虛擬主機連線. 使用 NAT Network 讓虛擬主機上網的另外一個好處是: Host 上 Virtualbox 的網路設定可以動態生效, 亦即 Ubuntu 20.04 可以一直保持在開機狀態, 使用者在 Host 端更動 Virtualbox 的 NAT Network 設定後, 即刻可以在 Ubuntu 虛擬主機上進行配合調適, 無需如 Bridged 或 Host Only 虛擬主機的網路設定, 必須關機後才能修改所使用的網路設定. NAT Network 上的 IPv4 與 IPv6 設定 由於在電腦輔助設計室使用純 IPv6 協定上網, 因此採用 NAT Network 設定的 Virtualbox 虛擬主機, 也必須能夠透過 IPv6 進行設定. NAT Network 的 DHCP 能同時支援 IPv4 與 IPv6, 但是在 GUI 介面只列出 IPv4 的 DHCP 內定使用 10.0.2.0/24 IP 位址, IPv6 的部分則需要透過指令才可列出: C:\\Users\\kmol2019>\"C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage\" list natnetworks NetworkName: NatNetwork IP: 10.0.2.1 Network: 10.0.2.0/24 IPv6 Enabled: Yes IPv6 Prefix: fd17:625c:f037:2::/64 DHCP Enabled: Yes Enabled: Yes loopback mappings (ipv4) 127.0.0.1=2 換言之, 在 Virtualbox 採用 NAT Network 設定的虛擬主機, 其 IPv4 gateway 預設為 10.0.2.1, 而 IPv6 的 gateway 則為 fd17:625c:f037:2::1, 了解此一訊息之後, 使用者就可以利用 Ｗindows 10 中的批次檔案 setnatnetwork.bat 來設定後續的網路內容, 主要讓 cd2020pj1 啟動後的 8443 與 7443 埠號伺服器, 能夠從 Host 瀏覽器中連線: \"C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage\" natnetwork modify --netname NatNetwork --port-forward-4 \"ssh:tcp:[127.0.0.1]:22:[10.0.2.4]:22\" \"C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage\" natnetwork modify --netname NatNetwork --port-forward-4 \"coppeliasim:tcp:[127.0.0.1]:19999:[10.0.2.4]:19999\" \"C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage\" natnetwork modify --netname NatNetwork --port-forward-4 \"cmsimde1:tcp:[127.0.0.1]:8443:[10.0.2.4]:8443\" \"C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage\" natnetwork modify --netname NatNetwork --port-forward-4 \"cmsimde2:tcp:[127.0.0.1]:7443:[10.0.2.4]:7443\" \"C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage\" natnetwork modify --netname NatNetwork --port-forward-6 \"ssh:tcp:[::1]:22:[fd17:625c:f037:2:a00:27ff:fef6:9b8a]:22\" \"C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage\" natnetwork modify --netname NatNetwork --port-forward-6 \"cmsimde1:tcp:[::1]:8443:[fd17:625c:f037:2:a00:27ff:fef6:9b8a]:8443\" \"C:\\Program Files\\Oracle\\VirtualBox\\VBoxManage\" natnetwork modify --netname NatNetwork --port-forward-6 \"cmsimde2:tcp:[::1]:7443:[fd17:625c:f037:2:a00:27ff:fef6:9b8a]:7443\" 其中 Ubuntu 20.04 虛擬主機的 netplan 網路設定為: network: ethernets: enp0s3: dhcp4: true dhcp6: true nameservers: addresses: - 2001:b000:168::1 version: 2 表示兩種網路協定都採用 DHCP, 但是 IPv6 必須設定 DNS 伺服器, 因為學校 DHCP6 所設定的 DNS 無法正確運作的緣故.","tags":"ubuntu","url":"./virtualbox-ubuntu-nat-network.html"},{"title":"gitlab 與 github 整合運用","text":"由於 github 遲遲不推出支援 IPv6 網站的連線功能, 目前若要在電腦輔助設計室直接透過純 IPv6 網路連線使用 git 分散式版次管理系統, 可以將 Github Pages 上的 CMSiMDE 網站, 同步一份倉儲資料到 Gitlab Pages . 機械設計工程師的網站 身為使用分散式版次管理系統的機械設計工程師團隊, 除了自行建立的 Linux 伺服器主機之外, Github Pages 是目前用來建立靜態網頁的最佳平台. 但是截至目前只支援 IPv4 網路協定連線的 github , 在上課時僅支援 IPv6 上線的情況下, 造成了許多不便. 因為所有的資料封包都必須透過雙支援的代理主機傳訊. 為了讓使用者可以在純 IPv6 環境下, 將 CMSiMDE 的靜態網頁部署在廣域雲端平台上, 準備將倉儲資料同步一份到 Gitlab Pages . 開放作風的 gitlab github 雖然比 gitlab 早創立幾年, 但是 gitlab 的開源與大器作風, 讓帳面價值達到 76 億美元的 github 失色許多. Github Pages 將用戶設定的靜態網頁資料分支, 以直覺但隱藏流程的方式進行, 導致許多情況下, 用戶無法就網頁資料轉檔流程進行除錯. gitlab-ci.yml 而 Gitlab Pages 則選擇讓使用自行透過 gitlab-ci.yml 的 YAML 檔案, 自行控制網頁的轉檔流程. 以 CMSiMDE 網際內容管理中的靜態網頁而言, 只要在倉儲資料根目錄中, 加入一個 gitlab-ci.yml 檔案, 內容如下: pages: stage: deploy script: - mkdir .public - cp -r * .public - mv .public public artifacts: paths: - public only: - master variables: GIT_SUBMODULE_STRATEGY: recursive 就可以順利將倉儲資料中的主分支靜態網頁, 部署在 https://帳號.gitlab.io/倉儲名稱 網址中. 其中最重要的設定參數: GIT_SUBMODULE_STRATEGY: recursive 就是表明要求 gitlab 在將倉儲轉為網頁的過程, 同時以 recursive 的方式將其中的 submodule 目錄, 也納入網頁的內容. git remote add 針對目前已經部署在 github 的靜態網頁倉儲, 使用者先在主分支的根目錄中, 新增提交推送一個上述的 gitlab-ci.yml 設定檔案, 然後建立與 github 帳號對應的 gitlab 帳號之後, 新增一個與 github 倉儲的同名空專案, 也就是連 README.md 都不建立的 public 空倉儲, 然後在近端倉儲主分支工作目錄中, 以: git remote add gitlab https://gitlab.com/帳號/同名倉儲.git 新增一個網址代號 gitlab, 指到上述 gitlab 系統中的空同名倉儲網址. 接下來就可以透過: git push gitlab 將 github 倉儲中的主分支資料, 同步一份到 gitlab , 並且在 gitlab-ci.yml 的設定導引下, 自動產生相應的 Gitlab Pages 靜態網頁. 而其網址就是: https://帳號.gitlab.io/倉儲名稱 最後, 假如之後的倉儲改版以 gitlab 為主, 只要在近端主分支的工作目錄中, 以: git remote add github https://github.com/帳號/同名倉儲.git 建立一個 github 代號倉儲連結, 就可以透過: git push github 將 github 當作 gitlab 倉儲的備份網站.","tags":"git","url":"./use-github-and-gitlab-pages.html"},{"title":"打造 Windows 隨身程式系統","text":"在 Windows 操作系統上開發套件, 不僅希望這個套件能夠在 Mac OS X 與 Linux 上運行, 而且整個程式環境都能放入一個 USB 隨身碟, 在任何一台乾淨的 64 位元 Windows 10 操作系統中都能正常運行. 不受限制, 因此需要打造一個隨身程式系統. 啟動批次檔案 從以下這個 start.bat 批次啟動檔案, 大致可以看出此一可攜程式系統所包含的內容: @echo off set Disk=y subst %Disk%: \"data\" %Disk%: set HomePath=%Disk%:\\home_no_proxy set HomeDrive=%Disk%:\\home_no_proxy set Home=%Disk%:\\home_no_proxy set USERPROFILE=%Disk%:\\home_no_proxy REM 將系統 Python 程式的 io 設為 utf-8 set PYTHONIOENCODING=\"utf-8\" set PYTHONPATH=%Disk%:\\Python38\\DLLs;%Disk%:\\Python38\\Lib;%Disk%:\\Python38\\Lib\\site-packages; set PYTHONHOME=%Disk%:\\Python38 REM for Java and Android SDK set java_home=%Disk%:\\java\\jdk8u222-b10 set ANDROID_SDK_home=%Disk%:\\home_no_proxy set GRADLE_USER_home=%Disk%:\\home_no_proxy set ANDROID_SDK_ROOT=%Disk%:\\android\\sdk set ANDROID_Home=%Disk%:\\android\\sdk set REPO_OS_OVERRIDE=windows REM 設定跟 Python 有關的命令搜尋路徑 set path_python=%Disk%:\\Python38;%Disk%:\\Python38\\Scripts; REM 設定跟Git 有關的命令搜尋路徑 set path_git=%Disk%:\\portablegit\\bin; REM 設定 msys2 64 位元的執行路徑 set path_msys2=%Disk%:\\msys64\\mingw64\\bin; REM set for LaTeX set path_miketex=%Disk%:\\miktex-portable\\texmfs\\install\\miktex\\bin\\x64; REM Flutter path set path_flutter=%Disk%:\\flutter\\bin;%java_home%\\bin;%Disk%:\\Android\\sdk;%Disk%:\\Android\\sdk\\tools;%Disk%:\\Android\\sdk\\tools\\bin;%Disk%:\\Android\\sdk\\emulator;%Disk%:\\Android\\sdk\\platform-tools;%Disk%:\\flutter\\bin\\cache\\dart-sdk\\bin;%Disk%:\\vscode; path=%Disk%:;%path_python%;%path_git%;%path_msys2%;%path_miketex%;%path_flutter%;%path%; start /MIN cmd.exe start /MIN cmd.exe start /MIN cmd.exe start /MIN cmd.exe start /MIN %Disk%:\\wScite\\SciTE.exe start /MIN %Disk%:\\wScite\\SciTE.exe Exit 關閉隨身系統的批次檔案 stop.bat, 只將 python, scite 與 dos 命令列關閉, 若需要關閉其他可能開啟的套件, 可以自行加入: @echo off set Disk=y path=%PATH%; taskkill /IM python.exe /F taskkill /IM pythonw.exe /F taskkill /IM scite.exe /F REM 終止虛擬硬碟與目錄的對應 subst %Disk%: /D REM 關閉 cmd 指令視窗 taskkill /IM cmd.exe /F EXIT 此一隨身系統安裝配置以 MSYS2 與 Flutter 較具挑戰性. MSYS2 首先與 MSYS2 的代理主機設定位於 Y:\\msys64\\etc\\wgetrc. 接下來為了可以編譯 C++ 程式, 必須安裝 pacman -S mingw-w64-x86_64-gcc 與 pacman -S mingw-w64-x86_64-toolchain 而列出 MSYS2 中所安裝的模組: pacman -Q 為了編譯 [Range3], 必須額外安裝: pacman -S mingw-w64-x86_64-ffmpeg pacman -S mingw-w64-x86_64-qt5 pacman -S mingw-w64-x86_64-qt5-static 編譯 Range3 git clone https://github.com/Range-Software/range3.git start Y:\\msys64\\mingw64.exe cd \\y\\tmp\\fem_ex\\range3 ./scripts/build.sh --clean && ./scripts/create_package.sh 而為了讓 svg 格式的 icons 能夠正確顯示, 必須納入 Qt5Svg.dll Flutter 至於現階段 Flutter 的安裝配置問題源自 Android sdk 的最新版 tools 與最新版的 Flutter 並不相容. 具體原因是: 目前的 Flutter 必須使用舊版的 Android sdk 中的舊版 tools. 使用者若從 Android 官方網站下載 tools 工具, 試圖與 Flutter 配合, 將會在執行: flutter doctor 時將出現 Android sdk licenses 尚未完成. 但是若再以: flutter doctor --android-licenses 就會出現 Java setting 錯誤. 解決方案 處理上述 Flutter 與最新版 Android 無法相容的問題, 必須借助: sdkmanager --sdk_root=y:\\android\\sdk tools 安裝舊版的 Android sdk tools, 問題是 sdkmanager 工具就位於 tools 目錄中, 因此必須先將新版的 tools 目錄改名為 tools_new, 並配合將 tools_new/bin 設為 start.bat 中的 PATH, 可攜系統啟動後, 以: sdkmanager --sdk_root=y:\\android\\sdk tools 安裝舊版的 Android sdk tools 後, 再將 PATH 路徑改為舊版 tools/bin. 之後再以 flutter doctor --android-licenses 同意使用授權後, 就可以接續進行 Flutter 套件的開發.","tags":"Windows","url":"./create-portable-win-prog-sys.html"},{"title":"倉儲資料維護與管理","text":"cd2020 是 2020 春季協同產品設計實習的課程網站, 而 cd2020pj1 則是與協同設計課程相關的程式專案, 兩者都採用 CMSiMDE 建立網站. 其中 cd2020 是典型的動態與網站架構, 而 cd2020pj1 則除了網站還包含 Flask 協同產品設計程式的開發. 當要從遠端 git clone cd2020 倉儲時, 牽涉到系統使用何種協定連線, https 或 ssh? 因為不同的連線協定有不同的設定檔案, 而且預計連線的主機並不一定就能提供服務, 因此能否順利完成 git clone 牽涉許多細節. 而這些細節並非一成不變, 而必須按照邏輯順序, 一一查驗才能得到期望中的結果. 首先, 因為 cd2020 網站的倉儲位於 https://github.com/mdecourse/cd2020.git, 其中帶有 cmsimde 子模組, 因此若要將此倉儲從遠端 git clone 到近端作為工作目錄, 最好的方式就是透過 --recurse-submodules 參數, 將子模組一起 clone 到近端. git clone --recurse-submodules https://github.com/mdecourse/cd2020.git 由於 KMOLab 的課程鼓勵學員在 Windows 10 操作系統中, 使用隨身程式系統, 而不要被微軟綁定, 因為使用者必須了解所開發的程式必須能在 Mac OS X 與許多 Linux 操作系統執行, Windows 10 不應該是工程師唯一的操作系統. 因此, 從隨身系統中的 start.bat 啟動後, Windows 10 就只是機械設計工程師的暫時宿主, 隨時都要準備離開, 所以啟動後必須注意所處的網路連線環境, 假如是在 IPv4 網路環境, 可以直接對 github.com 連線, 但是身處純 IPv6 網路環境中, 目前仍必須透過支援 IPv4 與 IPv6 的網路代理主機, 才能利用 git 或 ssh 對 github.com 連線. 以 https 對 github.com 連線, 代理主機的設定是透過: git config --global http.proxy=http://[2001::_your_ipv6_proxy]:3128 假如採 ssh 對 github.com 連線, 則代理主機的設定必須檢查 putty.exe 中 github.com session 中 Connections - Proxy 的代理主機設定. 一旦完成 cd2020 網站倉儲的 git clone, 使用者就可以使用隨身系統中的命令列視窗, 進入 cd2020 倉儲中的 cmsimde 目錄, 以: python wsgi.py 開啟動態網站系統, 並利用瀏覽器連線到 https://localhost:9443 進行動態網站內容的維護, 完成後再利用 generate pages 按鈕將動態網站中的 config/content.htm 轉為 content 目錄中的靜態網頁, 之後再新增, 提交, 推送到遠端, 以完成倉儲改版的流程.","tags":"Github","url":"./manage-your-cmsimde-site.html"},{"title":"CMSiMDE 部署","text":"CMSiMDE 所能伺服的內容包含網站, 網誌與簡報, 而網站又分為動態系統與靜態系統, 動態網站建置主要的目的在方便進行 html 文件的編輯, 而靜態網站系統則主要為了能在一般的 WWW 伺服器上進行部署. 網站 CMSiMDE 的網站編輯採用 Flask 框架編寫, 目前所需要的模組包含 flask, flask_cors, lxml, bs4 與 markdown. 使用者可以選擇將 CMSiMDE 當作 submodule 或者單獨部署在倉儲內容中的 cmsimde 目錄後, 再將 cmsimde 目錄中的 up_dir 目錄內容複製到倉儲主目錄即可. CMSiMDE 倉儲資料包含引擎內容 (也就是 cmsimde 中的資料) 與使用者內容 (也就是 up_dir 中的資料) 等兩類, 許多的網際功能都是配合歷年上課時敲敲打打修改而成, 因此整體架構相當鬆散, 就所謂的網際內容管理功能而言, 只能算勉強堪用, 還有很大的修改空間. 網誌 CMSiMDE 的網誌系統採用 Pelican , 編輯網誌的架構採用 Leo Editor 管理, 而網誌專案檔位於 config 目錄中的 pelican.leo. Leo Editor 其實是一套值得大力推廣的整合開發系統與文件編輯器, 但可能因為曲高因此和寡, 真正能夠運用上手的全球用戶, 數量始終偏低. 但是其大綱編輯模式非常適合處理複雜的工程設計流程所產生的各種文字資料, 因此非常希望 Python 新手能夠以看懂 Leo Editor 的設計架構與處理問題的細節作為遠大的目標. 簡報 CMSiMDE 的網誌簡報採用 reveal.js . 而簡報的編輯檔案也是採用 Leo Editor , 簡報專案位於 config 目錄中的 reveal.leo. 網站建構流程 CMSiMDE 的網站建構流程, 可以從建立初始的 Github 倉儲開始. 亦即在 Github 建立一個僅含 README.md 檔案的倉儲, 然後 git clone 該倉儲到近端後, 以命令列進入該倉儲後再以 git submodule add https://github.com/mdecourse/cmsimde.git cmsimde 將 CMSiMDE 倉儲內容納為子模組, 且命名為 cmsimde 目錄. 接下來將 cmsimde 目錄中, 名稱為 up_dir 的目錄內容, 複製到倉儲的根目錄中. 若近端隨身系統或操作系統已經安裝 Python3 與相應的 flask, flask_cors, lxml, bs4, markdown 等模組後, 就可以在命令列中, 進入 cmsimde 子目錄, 以: python wsgi.py 假如是在 OS X 或 Linux 操作系統, 則必須使用 Python 3 指令: python3 wsgi.py 在近端啟動動態網站, 以瀏覽器 https://localhost:9443 開啟. 網站內容管理 CMSiMDE 的動態網際內容管理, 將所有網頁內容存入 config 目錄中的 content.htm 檔案, 而在每一次使用者儲存新檔案之前, 會將舊版的 content.htm 複製至 content_backup.htm, 之所以如此是因為 CMSiMDE 採用 bs4 , 對 config/content.htm 內容進行分頁, 而分頁是依據 content.htm 由上到下的 h1, h2 與 h3 標註內容而定. 並在將動態網站內容 content.htm 以動態編輯器中的 generate pages 功能 (使用 lxml 模組功能) 轉為 content 目錄中的各分頁內容時, 可能因分頁失敗而讓整個 content.htm 內容丟失 (這就是非常需要改進的地方之一), 所以才設計 content_backup.htm 的複製進行及時補救. 另外, 在 CMSiMDE 將操作系統不允許作為檔案名稱的特殊符號自動移除之前 (例如 \":\" 號), 使用者應該避免在 h1, h2 與 h3 等標題中使用特殊符號. Github Pages 將 CMSiMDE 的動態系統轉為靜態後, 所有靜態頁面的內容存入 content 目錄, 使用者可以將此目錄內容部署到 Github Pages 上, 或其他能夠伺服 WWW html 檔案的系統即可完成網站的建立. 但是一般為了方便, 通常將包含動態系統與靜態網站內容的整個倉儲資料, 直接交由 Github 管理. 只要將倉儲的 master 分支設為 Github Pages 的根目錄, 就可以交由 Github Pages , 由倉儲主分支倉儲中的 index.html 進行網站導引. 假如使用者將近端的動態網頁內容轉為靜態後, 希望在近端檢視靜態網站內容, 可以在近端倉儲根目錄利用: python http-server.py 或在 OS X 及 Linux 操作系統中以: python3 http-server.py 啟動 https://localhost:8444 近端的靜態網頁伺服系統. Ubuntu 20.04 自架主機 上述利用 Github Pages 伺服 CMSiMDE 靜態網頁內容的配置流程非常簡單, 但若是要將 CMSiMDE 靜態網頁與動態網站系統部署在自架的 Ubuntu 20.04 主機, 則操作系統除了要安裝前述的 python3, flask, flask_cors, bs4, lxml, markdown 之外, 還需要運用 nginx , uwsgi , openssl 進行配置. 其中, openssl 用來建立網站認證用的 key 與 certificate, nginx 負責建立 WWW 伺服, 而 uwsgi 則負責用來開機執行 CMSiMDE 中的 wsgi.py 伺服程式. 利用 openssl 建立 cmsimde.key 與 cmsimde.crt 的指令如下: sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout cmsimde.key -out cmsimde.crt 與 uwsgi 有關的 Ubuntu 系統安裝則包括: // 安裝 pip3 sudo apt install python3-pip // 安裝 python 編譯開發系統 sudo apt install build-essential python3-dev // 安裝 uwsgi 模組 sudo pip3 install uwsgi // 安裝 nginx 伺服套件與 uwsgi python3 plugin 程式庫 sudo apt install nginx uwsgi-plugin-python3 /etc/nginx/sites-available/default # for lab.mde.tw static site, use nginx to serve server { listen 80 default_server; listen [::]:80 default_server; root /home/user_account/labmdetw; index index.html index.htm; server_name _; location /static { alias /home/user_account/labmdetw/cmsimde/static/; } location /downloads { alias /home/user_account/labmdetw/downloads/; } location /images { alias /home/user_account/labmdetw/images/; } location /blog { alias /home/user_account/labmdetw/blog/; } location /reveal { alias /home/user_account/labmdetw/reveal/; } location / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; } } # https://lab.mde.tw use nginx to serve server { listen 443 ssl; listen [::]:443 ssl; root /home/user_account/labmdetw; index index.html index.htm; server_name _; location /static { alias /home/user_account/labmdetw/cmsimde/static/; } location /downloads { alias /home/user_account/labmdetw/downloads/; } location /images { alias /home/user_account/labmdetw/images/; } location /blog { alias /home/user_account/labmdetw/blog/; } location /reveal { alias /home/user_account/labmdetw/reveal/; } location / { # First attempt to serve request as file, then # as directory, then fall back to displaying a 404. try_files $uri $uri/ =404; } ssl_certificate /etc/nginx/nginx.crt; ssl_certificate_key /etc/nginx/nginx.key; ssl_session_timeout 5m; ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers \"HIGH:!aNULL:!MD5 or HIGH:!aNULL:!MD5:!3DES\"; ssl_prefer_server_ciphers on; try_files $uri $uri/ =404; } # dynamic https://lab.mde.tw:7443 use nginx for ssl and uwsgi for wsgi serving server { listen 7443 ssl; listen [::]:7443 ssl; location /static { alias /home/user_account/labmdetw/cmsimde/static/; } location / { include uwsgi_params; uwsgi_pass 127.0.0.1:9443; } ssl_certificate /etc/nginx/nginx.crt; ssl_certificate_key /etc/nginx/nginx.key; ssl_session_timeout 5m; ssl_protocols SSLv3 TLSv1 TLSv1.1 TLSv1.2; ssl_ciphers \"HIGH:!aNULL:!MD5 or HIGH:!aNULL:!MD5:!3DES\"; ssl_prefer_server_ciphers on; try_files $uri $uri/ =404; } uwsgi_ini/uwsgi.ini [uwsgi] socket = 127.0.0.1:9443 uid = user_account gid = user_account plugins-dir = /usr/lib/uwsgi/plugins/ plugin = python3 master = true process = 4 threads = 2 chdir = /home/user_account/labmdetw/cmsimde wsgi-file = /home/user_account/labmdetw/cmsimde/wsgi.py 啟動 uwsgi 指令, 將會逐一啟動 wsgi_ini 目錄中個別 .ini 檔案: sudo /usr/bin/uwsgi --emperor /home/user_account/wsgi_ini 最後則設定 Ubuntu 系統服務, 用來啟動 uwsgi: /etc/systemd/system 的 cmsimde.service 服務啟動檔案內容: [Unit] Description=uWSGI to serve CMSiMDE After=network.target [Service] User=user_account Group=user_account WorkingDirectory=/home/user_account/uwsgi_ini ExecStart=/usr/local/bin/uwsgi --emperor /home/user_account/uwsgi_ini [Install] WantedBy=multi-user.target 接著將 cmsimde 服務設為隨系統開機啟動: sudo systemctl enable cmsimde 若要取消 cmsimde 服務隨系統開機啟動: sudo systemctl disable cmsimde 手動啟動 cmsimde.service 服務 sudo systemctl start cmsimde 手動停止 cmsimde.service 服務 sudo systemctl stop cmsimde","tags":"Github","url":"./2020-lab-get-started.html"}]};